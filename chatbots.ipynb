{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca18bab3",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "In this module We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "613b020d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## Loading all the environment variable\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc23ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"GROQ_API_KEY\"))  # Should print your key if set correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ee6d56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001A790A77980>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001A7909B7AD0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\",groq_api_key = groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca69e598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Hargovind Ahirwar! It's nice to meet you.  \\n\\nThat's great that you're an AI engineer. It's a fascinating field with so much potential. What kind of work do you do in AI? Are you working on any exciting projects right now? \\n\\nI'm always eager to learn more about what people are doing in the world of AI.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 26, 'total_tokens': 111, 'completion_time': 0.154545455, 'prompt_time': 0.005126689, 'queue_time': 0.75552129, 'total_time': 0.159672144}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--7b17e822-bab2-42f5-9bda-49bdb1735761-0', usage_metadata={'input_tokens': 26, 'output_tokens': 85, 'total_tokens': 111})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi , My name is Hargovind Ahirwar and I am a AI engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb8b07d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Hargovind Ahirwar and that you are an AI engineer.  \\n\\nIs there anything else you'd like to talk about? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 49, 'total_tokens': 88, 'completion_time': 0.070909091, 'prompt_time': 0.008510882, 'queue_time': 0.412936888, 'total_time': 0.079419973}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--a15dc068-0f27-4858-af43-44309465a9c6-0', usage_metadata={'input_tokens': 49, 'output_tokens': 39, 'total_tokens': 88})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi ,My name is Hargovind Ahirwar and I am a AI enginee\"),\n",
    "    \n",
    "    HumanMessage(content=\"hey What 's my name and what do i do?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d0b9e",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09dec476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0e7eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8bc7e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi , My name is Hargovind Ahirwar and I am a AI Engineer\")]},\n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87aa9497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Hargovind Ahirwar, it's great to meet you!\\n\\nWhat kind of AI engineering are you involved in?  Do you specialize in a particular area like machine learning, natural language processing, computer vision, or something else? \\n\\nI'm always curious to learn about the different applications and challenges faced by AI engineers.\\n\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d87981b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Hargovind Ahirwar.  üòä  \\n\\nI remembered it from our earlier conversation!  \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 202, 'total_tokens': 239, 'completion_time': 0.067272727, 'prompt_time': 0.012692253, 'queue_time': 0.243616866, 'total_time': 0.07996498}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--c695c17b-6010-46a5-9777-5d4817a1b6ef-0', usage_metadata={'input_tokens': 202, 'output_tokens': 37, 'total_tokens': 239})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2 = with_message_history.invoke([\n",
    "    HumanMessage(content=\"What is my name?\")\n",
    "],config= config)\n",
    "\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49853461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an open-weights AI assistant, here are some of the things I can do:\\n\\n**Communication and Language:**\\n\\n* **Generate creative content:** Write stories, poems, articles, dialogue, and more.\\n* **Translate languages:** Translate text between different languages.\\n* **Summarize text:** Provide concise summaries of longer pieces of writing.\\n* **Answer questions:** Answer your questions based on the information I have been trained on.\\n* **Engage in conversation:** Have a natural-sounding conversation on a variety of topics.\\n\\n**Code and Data:**\\n\\n* **Generate code:** Write code in multiple programming languages.\\n* **Explain code:** Provide explanations and comments for existing code.\\n* **Identify patterns in data:** Analyze data and identify trends or patterns.\\n\\n**Other Capabilities:**\\n\\n* **Brainstorm ideas:** Help you generate new ideas for projects or problems.\\n* **Provide definitions and explanations:** Define words and concepts.\\n* **Create lists and outlines:** Organize your thoughts and ideas.\\n* **Offer suggestions and recommendations:** Give you suggestions for books, movies, or other resources.\\n\\n**Limitations:**\\n\\n* **I am not connected to the internet:** I cannot access real-time information or perform Google searches.\\n* **My knowledge is limited to my training data:** I may not have information on recent events or specialized topics.\\n* **I am not a substitute for professional advice:** I cannot provide medical, legal, or financial advice.\\n\\n**Ethical Considerations:**\\n\\n* **Bias:** I may exhibit biases present in the data I was trained on.\\n\\nIt's important to use me responsibly and critically evaluate the information I provide.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 344, 'prompt_tokens': 13, 'total_tokens': 357, 'completion_time': 0.625454545, 'prompt_time': 0.001902766, 'queue_time': 0.246699814, 'total_time': 0.627357311}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--fcd7c120-d7a5-442a-9645-9b8f0959aa6f-0', usage_metadata={'input_tokens': 13, 'output_tokens': 344, 'total_tokens': 357})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {\"configurable\":{\"session_id\":\"chat2\"}\n",
    "}\n",
    "response3 = with_message_history.invoke([\n",
    "    HumanMessage(content=\"What you can do\")\n",
    "],config=config2)\n",
    "\n",
    "response3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00bdd550",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke([\n",
    "    HumanMessage(content=\"Hey , my name is Ajay and I am passionate AI engineer . My father is owner of Alifera construction\")\n",
    "    \n",
    "],config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "16a85427",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke([\n",
    "    HumanMessage(content=\"Hey , what you know  about me? \")\n",
    "    \n",
    "],config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7b83cc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on our conversation so far, I know that:\\n\\n* Your name is Ajay.\\n* You're passionate about AI engineering.\\n* Your father owns a construction company called Alifera.\\n\\nIs there anything else you'd like me to know about you? I'm always eager to learn more! üòä  \\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54abc333",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9277d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\"Ypu are a helpful assistant . Answer all the question to the best of your ablilty\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4026124a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Krish! It's nice to meet you.\\n\\nI'm happy to help with any questions you have.  Just ask away! üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 33, 'total_tokens': 67, 'completion_time': 0.061818182, 'prompt_time': 0.002363786, 'queue_time': 0.246693644, 'total_time': 0.064181968}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--f2966de1-d600-48a2-9319-541865b2266d-0', usage_metadata={'input_tokens': 33, 'output_tokens': 34, 'total_tokens': 67})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\" : [HumanMessage(content=\"Hi My name is Krish\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da289f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7bc8a9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Hargovind Ahirwar! It's nice to meet you. \\n\\nPlease ask me anything! I'll do my best to help. üòä  What can I do for you today? \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 38, 'total_tokens': 84, 'completion_time': 0.083636364, 'prompt_time': 0.002344785, 'queue_time': 0.244261638, 'total_time': 0.085981149}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--2970b2a1-c01f-4478-9374-a3cf3f2303f3-0', usage_metadata={'input_tokens': 38, 'output_tokens': 46, 'total_tokens': 84})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config4 = {\"configurable\": {\"session_id\" : \"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hi My name is Hargovind Ahirwar\")\n",
    "    ],\n",
    "    config=config4\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ffaaeeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Hargovind Ahirwar!  \\n\\nI'm designed to remember information from our conversations. \\n\\nIs there something specific you'd like to talk about, Hargovind?\\n\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88618a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity \n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\"You are a helpful assistant. Answer all questions to the best of your ability in{language}.\",),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    \n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda0157",
   "metadata": {},
   "source": [
    "response = chain.invoke({\n",
    "    \"messages\":[HumanMessage(content=\"hi my name is Hargovind\")] , \"language\":\"hindi\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1eb076a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c59431",
   "metadata": {},
   "source": [
    "Let's now wrap this more complicated chain in a Message History class. This time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cdacdad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_messages_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "edcc1fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§π‡§∞‡•ç‡§ó‡•ã‡§µ‡§ø‡§Ç‡§¶! ‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§∏‡•á ‡§Æ‡§ø‡§≤‡§®‡•á ‡§ï‡•ã ‡§Æ‡§ø‡§≤‡§æ‡•§ \\n\\n‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•Ç‡§Å‡•§ üòä\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    \n",
    "        {'messages':[HumanMessage(content=\"Hi , my name is hargovind\")],\"language\":\"Hindi\"},\n",
    "        config=config\n",
    "    \n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d1c87ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Hindi\"},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8a227f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§π‡§∞‡•ç‡§ó‡•ã‡§µ‡§ø‡§Ç‡§¶ ‡§π‡•à‡•§  üòä \\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb4d0e",
   "metadata": {},
   "source": [
    "### Managing the Conversation History\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7cf74750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage , trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy= \"last\",\n",
    "    token_counter = model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"Hi ! I'm Ajay\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"what is 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"thanks\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ba4c0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Æ‡•Å‡§ù‡•á ‡§®‡§π‡•Ä‡§Ç ‡§™‡§§‡§æ ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§ï‡§ø‡§∏ ‡§§‡§∞‡§π ‡§ï‡§æ ‡§Ü‡§á‡§∏‡§ï‡•ç‡§∞‡•Ä‡§Æ ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à! ‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§™‡§∏‡§Ç‡§¶ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§è‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§¨‡•á‡§π‡§§‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡•Ç‡§Ç.  ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•á ‡§™‡§∏‡§Ç‡§¶‡•Ä‡§¶‡§æ ‡§Ü‡§á‡§∏‡§ï‡•ç‡§∞‡•Ä‡§Æ ‡§´‡•ç‡§≤‡•á‡§µ‡§∞ ‡§π‡•à‡§Ç? üòãüç¶\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")| trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\":messages+[HumanMessage(content=\"what ice cream do i like\")],\n",
    "        \"language\":\"Hindi\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5af7ae6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§§‡•Å‡§Æ‡§®‡•á 2 + 2 ‡§ï‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡§æ ‡§•‡§æ. \\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"Hindi\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b08da719",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the Message History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config = {\"configurable\":{\"session_id\":\"chat5\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed971e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to past conversations or any personal information about you, including your name.  \\n\\nWould you like to tell me your name? üòä  \\n\\n\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9b08a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je suis d√©sol√©, mais je n'ai pas de m√©moire des conversations pass√©es. Pourrais-tu me reformuler ta question ? üòä  \\n\\n\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"French\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab141902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
